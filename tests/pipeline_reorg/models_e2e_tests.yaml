# This file defines the test matrix for the Models End-To-End Tests pipelines.
#
# Each entry represents a parallel job with the following keys:
#   name: The display name for the job in GitHub Actions.
#   cmd: The exact command to run (env vars must be inlined).
#   model: Model identifier for filtering (workflow_dispatch model selection).
#   skus: A mapping of SKU names to their configuration:
#     timeout: Job timeout in minutes.
#     tier: Model tier (1, 2, or 3) used to filter which pipeline runs this test.
#   owner_id: The Slack user ID to notify on failure.
#   team: The team that owns the test.

# For max allowed timeout refer to .github/time_budget.yaml

- name: Llama 3.1-8B e2e tests
  cmd: |
    export HF_MODEL=meta-llama/Llama-3.1-8B-Instruct TT_CACHE_PATH=/mnt/MLPerf/huggingface/tt_cache/meta-llama/Llama-3.1-8B-Instruct
    pytest --timeout 420 models/tt_transformers/demo/simple_text_demo.py -k "performance-ci-token-matching"
    pytest --timeout 600 models/tt_transformers/demo/simple_text_demo.py -k "performance-ci-eval-32"
  model: llama3.1-8b
  skus:
    wh_n150:
      timeout: 10
      tier: 1
    wh_llmbox_perf:
      timeout: 30
      tier: 2
  owner_id: U03PUAKE719 # Miguel Tairum Cruz
  team: models

- name: Llama 3.2-1B e2e tests
  cmd: |
    export HF_MODEL=meta-llama/Llama-3.2-1B-Instruct TT_CACHE_PATH=/mnt/MLPerf/huggingface/tt_cache/meta-llama/Llama-3.2-1B-Instruct
    pytest --timeout 420 models/tt_transformers/demo/simple_text_demo.py -k "performance-ci-token-matching"
  model: llama3.2-1b
  skus:
    wh_n150:
      timeout: 5
      tier: 3
    wh_n300:
      timeout: 5
      tier: 3
  owner_id: U03PUAKE719 # Miguel Tairum Cruz
  team: models

- name: Llama 3.2-3B e2e tests
  cmd: |
    export HF_MODEL=meta-llama/Llama-3.2-3B-Instruct TT_CACHE_PATH=/mnt/MLPerf/huggingface/tt_cache/meta-llama/Llama-3.2-3B-Instruct
    pytest --timeout 420 models/tt_transformers/demo/simple_text_demo.py -k "performance-ci-token-matching"
  model: llama3.2-3b
  skus:
    wh_n150:
      timeout: 5
      tier: 3
    wh_n300:
      timeout: 5
      tier: 3
  owner_id: U03PUAKE719 # Miguel Tairum Cruz
  team: models

- name: Llama 3.3-70B e2e tests
  cmd: |
    export HF_MODEL=meta-llama/Llama-3.3-70B-Instruct TT_CACHE_PATH=/mnt/MLPerf/huggingface/tt_cache/meta-llama/Llama-3.3-70B-Instruct
    pytest --timeout 420 models/tt_transformers/demo/simple_text_demo.py -k "performance-ci-token-matching"
    pytest --timeout 1800 models/tt_transformers/demo/simple_text_demo.py -k "performance-ci-eval-32"
  model: llama3.3-70b
  skus:
    wh_llmbox_perf:
      timeout: 30
      tier: 2
  owner_id: U03PUAKE719 # Miguel Tairum Cruz
  team: models

- name: Llama 3.3-70B e2e tests (Galaxy)
  cmd: |
    export TT_CACHE_HOME=/mnt/MLPerf/huggingface/tt_cache LLAMA_DIR=/mnt/MLPerf/tt_dnn-models/llama/Llama3.3-70B-Instruct/ FAKE_DEVICE=TG
    pytest --timeout 1000 models/demos/llama3_70b_galaxy/demo/text_demo.py -k "pcc-80L"
    pytest --timeout 1000 models/demos/llama3_70b_galaxy/demo/text_demo.py -k "evals-32"
  model: llama3.3-70b-galaxy
  skus:
    wh_galaxy:
      timeout: 30
      tier: 1
  owner_id: U03PUAKE719 # Miguel Tairum Cruz
  team: models
